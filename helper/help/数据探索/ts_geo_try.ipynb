{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Forceasting with decompasable model\n",
    "from pylab import rcParams\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Datetime operations\n",
    "import time\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import folium\n",
    "from fbprophet import Prophet\n",
    "plt.style.use('fivethirtyeight')\n",
    "import pickle\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "train = pd.read_csv(\"d:/zillow/train_2016_v2.csv\", parse_dates=[\"transactiondate\"])\n",
    "prop = pd.read_csv('d:/zillow/properties_2016.csv')\n",
    "df_train = train.merge(prop, how='left', on='parcelid')\n",
    "end = time.time()\n",
    "print(\"time taken by thie script by now is {} sec.\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据类型转换\n",
    "for c, dtype in zip(df_train.columns, df_train.dtypes):\n",
    "    if dtype == np.float64:\n",
    "        df_train[c] = df_train[c].astype(np.float32) \n",
    "    elif dtype == np.int64:\n",
    "        df_train[c] = df_train[c].astype(np.int32) \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#时间格式转化\n",
    "df_train['transaction_month'] = df_train['transactiondate'].dt.month\n",
    "df_train['transaction_year'] = df_train['transactiondate'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#单变量分析\n",
    "me = np.mean(df_train['logerror']); med = np.median(df_train['logerror']); st = df_train['logerror'].std(); \n",
    "print(df_train['logerror'].describe())\n",
    "\n",
    "x = df_train['logerror']\n",
    "f, (ax_box, ax_hist) = plt.subplots(2, sharex=True ,\n",
    "                                    gridspec_kw={\"height_ratios\": (.15, .85)})\n",
    "sns.boxplot(x, ax=ax_box)\n",
    "sns.distplot(x, ax=ax_hist, bins=400, kde=False)\n",
    "ax_box.set(yticks=[])\n",
    "sns.despine(ax=ax_hist)\n",
    "sns.despine(ax=ax_box, left=True)\n",
    "plt.xlim([me-2*st, me+2*st])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#多变量分析\n",
    "df_train.loc[:,'abs_logerror'] = df_train['logerror'].abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.palettes import Spectral4\n",
    "from bokeh.plotting import figure, output_notebook, show\n",
    "\n",
    "fips1 = pd.DataFrame(df_train.loc[df_train['fips']==6037].groupby('transactiondate')['abs_logerror'].mean())\n",
    "fips1.reset_index(inplace = True)\n",
    "fips2 = pd.DataFrame(df_train.loc[df_train['fips']==6059].groupby('transactiondate')['abs_logerror'].mean())\n",
    "fips2.reset_index(inplace = True)\n",
    "fips3 = pd.DataFrame(df_train.loc[df_train['fips']==6111].groupby('transactiondate')['abs_logerror'].mean())\n",
    "fips3.reset_index(inplace = True)\n",
    "\n",
    "\n",
    "output_notebook()\n",
    "out = figure(plot_width=800, plot_height=250, x_axis_type=\"datetime\")\n",
    "\n",
    "for data, name, color in zip([fips1, fips2, fips3], [\"Los Angeles\", \"Orange County\", \"Ventura County\"], Spectral4):\n",
    "\n",
    "    out.line(data['transactiondate'], data['abs_logerror'], line_width=2, color=color, alpha=0.8, legend=name)\n",
    "\n",
    "out.legend.location = \"top_left\"\n",
    "out.legend.click_policy=\"hide\"\n",
    "show(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fips1 = pd.DataFrame(df_train.loc[df_train['fips']==6037].groupby('yearbuilt')['abs_logerror'].mean())\n",
    "fips1.reset_index(inplace = True)\n",
    "fips2 = pd.DataFrame(df_train.loc[df_train['fips']==6059].groupby('yearbuilt')['abs_logerror'].mean())\n",
    "fips2.reset_index(inplace = True)\n",
    "fips3 = pd.DataFrame(df_train.loc[df_train['fips']==6111].groupby('yearbuilt')['abs_logerror'].mean())\n",
    "fips3.reset_index(inplace = True)\n",
    "\n",
    "output_notebook()\n",
    "out = figure(plot_width=800, plot_height=250)\n",
    "\n",
    "for data, name, color in zip([fips1, fips2, fips3], [\"Los Angeles\", \"Orange County\", \"Ventura County\"], Spectral4):\n",
    "\n",
    "    out.line(data['yearbuilt'], data['abs_logerror'], line_width=2, color=color, alpha=0.8, legend=name)\n",
    "\n",
    "out.legend.location = \"top_right\"\n",
    "out.legend.click_policy=\"hide\"\n",
    "show(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly # visualization\n",
    "from plotly.graph_objs import Scatter, Figure, Layout # visualization\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot,iplot # visualization\n",
    "import plotly.figure_factory as ff # visualization\n",
    "import plotly.graph_objs as go # visualization\n",
    "init_notebook_mode(connected=True) # visualization\n",
    "\n",
    "worst_prediction = df_train['abs_logerror'].quantile(q=.95)\n",
    "\n",
    "\n",
    "trace0 = go.Scatter(\n",
    "    y = df_train[(df_train['fips']==6037)&(df_train['abs_logerror']>worst_prediction)].\\\n",
    "                groupby('yearbuilt')['abs_logerror'].mean(),\n",
    "    x = df_train[(df_train['fips']==6037)&(df_train['abs_logerror']>worst_prediction)].\\\n",
    "                groupby('yearbuilt')['abs_logerror'].mean().index,\n",
    "    mode = 'lines+markers',\n",
    "    name = \"Los Angeles\", \n",
    ")\n",
    "trace1 = go.Scatter(\n",
    "    y = df_train[(df_train['fips']==6059)&(df_train['abs_logerror']>worst_prediction)].\\\n",
    "                groupby('yearbuilt')['abs_logerror'].mean(),\n",
    "    x = df_train[(df_train['fips']==6059)&(df_train['abs_logerror']>worst_prediction)].\\\n",
    "                groupby('yearbuilt')['abs_logerror'].mean().index,\n",
    "    mode = 'lines+markers',\n",
    "    name = \"Orange County\"\n",
    ")\n",
    "trace2 = go.Scatter(\n",
    "    y = df_train[(df_train['fips']==6111)&(df_train['abs_logerror']>worst_prediction)].\\\n",
    "                groupby('yearbuilt')['abs_logerror'].mean(),\n",
    "    x = df_train[(df_train['fips']==6111)&(df_train['abs_logerror']>worst_prediction)].\\\n",
    "                groupby('yearbuilt')['abs_logerror'].mean().index,\n",
    "    mode = 'lines+markers',\n",
    "    name = \"Ventura County\"\n",
    ")\n",
    "data = [trace0, trace1, trace2]\n",
    "\n",
    "plotly.offline.iplot(data, filename='line-mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_df = df_train[['latitude', 'longitude','logerror']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_df['longitude']/=1e6\n",
    "geo_df['latitude']/=1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_df.dropna(subset=['latitude','longitude'], axis=0 ,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "kmeans = MiniBatchKMeans(n_clusters=120, batch_size=1000).fit(geo_df[['latitude','longitude']])\n",
    "geo_df.loc[:, 'label'] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_2 = folium.Map(location=[34.088537, -118.249923],\n",
    "                   zoom_start=9)\n",
    "for label in kmeans.cluster_centers_:\n",
    "    folium.Marker(location=[label][0]).add_to(map_2)\n",
    "\n",
    "map_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_1 = folium.Map(location=[34.088537, -118.249923], zoom_start=9,\n",
    "                   tiles='Stamen Terrain')\n",
    "for label in kmeans.cluster_centers_:\n",
    "    folium.Marker(location=[label][0]).add_to(map_1)\n",
    "map_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del map_2 ,map_1\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "perfect_geo_df = geo_df[geo_df['logerror']==0]\n",
    "perfect_geo_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_perfect = folium.Map(location=[34.088537, -118.249923], zoom_start=9,\n",
    "                   tiles='Stamen Toner')\n",
    "for lat, lon in zip(perfect_geo_df.latitude, perfect_geo_df.longitude):\n",
    "    folium.Marker(location=[lat,lon]).add_to(map_perfect)\n",
    "map_perfect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del perfect_geo_df, map_perfect, geo_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 6))\n",
    "mean_group = df_train[['transactiondate','abs_logerror']].groupby(['transactiondate'])['abs_logerror'].mean()\n",
    "plt.plot(mean_group)\n",
    "plt.xlabel('Date', fontsize=15)\n",
    "plt.ylabel('Absolute Log error', fontsize=15)\n",
    "plt.title('Time Series - Average')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 6)) \n",
    "fips1 = pd.DataFrame(df_train.loc[df_train['fips']==6037].groupby('transactiondate')['abs_logerror'].mean())\n",
    "plt.plot(fips1,c='k')\n",
    "plt.xlabel('Date', fontsize=15)\n",
    "plt.ylabel('Absolute Log error', fontsize=15)\n",
    "plt.title('Time Series Los Angeles - Average')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 6)) \n",
    "fips1 = pd.DataFrame(df_train.loc[df_train['fips']==6059].groupby('transactiondate')['abs_logerror'].mean())\n",
    "plt.plot(fips1, c = 'm')\n",
    "plt.xlabel('Date', fontsize=15)\n",
    "plt.ylabel('Absolute Log error', fontsize=15)\n",
    "plt.title('Time Series Orange County - Average')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 6))\n",
    "fips1 = pd.DataFrame(df_train.loc[df_train['fips']==6111].groupby('transactiondate')['abs_logerror'].mean())\n",
    "plt.plot(fips1, c = 'y')\n",
    "plt.xlabel('Date', fontsize=15)\n",
    "plt.ylabel('Absolute Log error', fontsize=15)\n",
    "plt.title('Time Series Ventura County - Average')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 6))\n",
    "median_group = df_train[['transactiondate','abs_logerror']].groupby(['transactiondate'])['abs_logerror'].median()\n",
    "plt.plot(median_group, c='b')\n",
    "plt.xlabel('Date', fontsize=15)\n",
    "plt.ylabel('Absolute Log error', fontsize=15)\n",
    "plt.title('Time Series - Median')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 6))\n",
    "std_group = df_train[['transactiondate','abs_logerror']].groupby(['transactiondate'])['abs_logerror'].median()\n",
    "plt.plot(std_group, c='g')\n",
    "plt.xlabel('Date', fontsize=15)\n",
    "plt.ylabel('Absolute Log error', fontsize=15)\n",
    "plt.title('Time Series - STD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del mean_group, median_group, std_group\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[df_train['abs_logerror']<  me + st ]\n",
    "mean_group = df_train[['transactiondate','abs_logerror']].groupby(['transactiondate'])['abs_logerror'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_series_means =  pd.DataFrame(mean_group).reset_index(drop=False)\n",
    "df_date_index = times_series_means[['transactiondate','abs_logerror']].set_index('transactiondate')\n",
    "decomposition = sm.tsa.seasonal_decompose(df_date_index, model='additive',freq = 31)\n",
    "trend = decomposition.trend\n",
    "seasonal = decomposition.seasonal\n",
    "residual = decomposition.resid\n",
    "rcParams['figure.figsize'] = 15, 8\n",
    "\n",
    "plt.subplot(411)\n",
    "plt.title('Obesered = Level + Trend + Seasonality + Noise ')\n",
    "plt.plot(df_date_index, label='Observed')\n",
    "plt.legend(loc='best')\n",
    "plt.subplot(412)\n",
    "plt.plot(trend, label='Trend')\n",
    "plt.legend(loc='best')\n",
    "plt.subplot(413)\n",
    "plt.plot(seasonal,label='Seasonality')\n",
    "plt.legend(loc='best')\n",
    "plt.subplot(414)\n",
    "plt.plot(residual, label='Residuals')\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_series_means =  pd.DataFrame(mean_group).reset_index(drop=False)\n",
    "df_date_index = times_series_means[['transactiondate','abs_logerror']].set_index('transactiondate')\n",
    "decomposition = sm.tsa.seasonal_decompose(df_date_index, model='multiplicative',freq = 120)\n",
    "trend = decomposition.trend\n",
    "seasonal = decomposition.seasonal\n",
    "residual = decomposition.resid\n",
    "rcParams['figure.figsize'] = 15, 8\n",
    "\n",
    "plt.subplot(411)\n",
    "plt.title('Obesered = Level x Trend x Seasonality x Noise ')\n",
    "plt.plot(df_date_index, label='Observed')\n",
    "plt.legend(loc='best')\n",
    "plt.subplot(412)\n",
    "plt.plot(trend, label='Trend')\n",
    "plt.legend(loc='best')\n",
    "plt.subplot(413)\n",
    "plt.plot(seasonal,label='Seasonality')\n",
    "plt.legend(loc='best')\n",
    "plt.subplot(414)\n",
    "plt.plot(residual, label='Residuals')\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_stationarity(timeseries):\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    #Determing rolling statistics\n",
    "    rolmean = pd.rolling_mean(timeseries, window=31) # Slide window depend on past 1 month\n",
    "    rolstd = pd.rolling_std(timeseries, window=31)\n",
    "\n",
    "    #Plot rolling statistics:\n",
    "    orig = plt.plot(timeseries, color='blue',label='Original')\n",
    "    mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n",
    "    std = plt.plot(rolstd, color='black', label = 'Rolling Std')\n",
    "    plt.legend(loc='best', fontsize=15)\n",
    "    plt.title('Rolling Mean & Standard Deviation', fontsize=15)\n",
    "    plt.xlabel('Date', fontsize=15)\n",
    "    plt.ylabel('Absolute Log Error', fontsize=15)\n",
    "    plt.show(block=False)\n",
    "    \n",
    "    #Perform Dickey-Fuller test:\n",
    "    print('Results of Dickey-Fuller Test:')\n",
    "    dftest = sm.tsa.adfuller(timeseries['abs_logerror'], autolag='AIC')\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "    for key,value in dftest[4].items():\n",
    "        dfoutput['Critical Value (%s)'%key] = value\n",
    "    print(dfoutput)\n",
    "    \n",
    "test_stationarity(df_date_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1) \n",
    "df_prophet =  pd.DataFrame(mean_group).reset_index(drop=False)\n",
    "df_prophet = df_prophet.iloc[-92:,:] # Forecast due to past 3 months\n",
    "df_prophet.columns = ['ds','y']\n",
    "\n",
    "m = Prophet()\n",
    "m.fit(df_prophet)\n",
    "future = m.make_future_dataframe(periods=59,freq='D') # Forecast Jan 2017\n",
    "forecast = m.predict(future)\n",
    "plt.figure(figsize=(30, 6))\n",
    "fig = m.plot(forecast)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}